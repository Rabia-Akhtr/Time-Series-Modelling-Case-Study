{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rabia-Akhtr/Time-Series-Modelling-Case-Study/blob/main/Assignment_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOi7kU7BE4wy"
      },
      "source": [
        "# A case study on modelling some real data, finding the best model to describe the data, then making a forecast.\n",
        "\n",
        "I will use the Oil prices data.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SkTGEklmE-6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZaAwUrg7VTg"
      },
      "outputs": [],
      "source": [
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# System\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Fix random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA10X4UgE4w4"
      },
      "outputs": [],
      "source": [
        "# Read in the data and check its OK\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Advance Research/Assignment 1/oil_price.csv', parse_dates=['Date'])\n",
        "data.set_index('Date', inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "OffSq3Ca7jBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "yI47ugxs7kKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "pd.concat([data.head(), data.tail()])"
      ],
      "metadata": {
        "id": "khnGX5Mk7tXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly = data['Price'].resample('M').mean().dropna()\n",
        "print(f\"Loaded {len(monthly)} months from {monthly.index.min().date()} to {monthly.index.max().date()}\")"
      ],
      "metadata": {
        "id": "JdSHSfjI9A2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Null values\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "DLwUENhl7yHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the dataset\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "0meMrL3B704g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We scale the oil price data to the range [0, 1] to make the LSTM model training more stable and efficient. Scaling also helps prevent issues with very large or small values that can slow learning."
      ],
      "metadata": {
        "id": "DCAu1UNqELWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_data(series: pd.Series, feature_range: tuple = (0, 1)):\n",
        "    \"\"\"\n",
        "    Scale a 1D numeric pandas Series to a given range.\n",
        "    Returns the scaled array and fitted scaler.\n",
        "    \"\"\"\n",
        "    values = series.values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler(feature_range=feature_range)\n",
        "    scaled_array = scaler.fit_transform(values)\n",
        "    return scaled_array, scaler\n",
        "\n",
        "# Call the function and view results\n",
        "monthly_scaled, scaler = scale_data(monthly)\n",
        "print(\"Scaled array shape:\", monthly_scaled.shape)"
      ],
      "metadata": {
        "id": "FK4SB83WCl8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert the time series into input/output pairs for supervised learning.\n",
        "Each input sequence consists of look_back previous values (e.g., last 12 months), and the target is the next value.\n",
        "We also split the data into training and testing sets."
      ],
      "metadata": {
        "id": "1jY70AvzEV_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## One‐Step Sequence Function\n",
        "import numpy as np\n",
        "\n",
        "def create_one_step_sequences(scaled_array: np.ndarray, look_back: int = 12):\n",
        "    \"\"\"\n",
        "    Build X, y for one‐step‐ahead forecasting:\n",
        "      X[i] = scaled_array[i : i+look_back]\n",
        "      y[i] = scaled_array[i+look_back, 0]\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    total = len(scaled_array)\n",
        "    for i in range(total - look_back):\n",
        "        X.append(scaled_array[i : i + look_back])\n",
        "        y.append(scaled_array[i + look_back, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "look_back = 12\n",
        "X, y = create_one_step_sequences(monthly_scaled, look_back=look_back)\n",
        "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "id": "UDkxrn_4_fLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Validation Split\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, y_train = X[:split_idx], y[:split_idx]\n",
        "X_val,   y_val   = X[split_idx:], y[split_idx:]\n",
        "print(\"Train samples:\", X_train.shape[0], \"Val samples:\", X_val.shape[0])\n"
      ],
      "metadata": {
        "id": "HUUFLYom_i31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ4tmxukE4w6"
      },
      "source": [
        "# Build and Train the LSTM Model\n",
        "\n",
        "We will now define and train the LSTM model using our processed data.\n",
        "The model will learn to predict the next oil price given the previous 12 months of prices.\n",
        "We will evaluate the model’s performance using the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model‐Building Function for One‐Step (Iterative) Forecast (No Dropout)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "def build_lstm_model(input_shape, units=50, optimizer='adam'):\n",
        "    \"\"\"\n",
        "    Build and compile a one-step LSTM model for iterative forecasting.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        LSTM(units, activation='tanh', input_shape=input_shape),\n",
        "        Dense(1)    # predict the next single step\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Example instantiation with look_back=12:\n",
        "model = build_lstm_model(input_shape=(look_back, 1), units=50)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "72sDn3aN-5__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hypertune Parameters with Grid Search**"
      ],
      "metadata": {
        "id": "ltLLB1cwF6At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning Loop (iterative one‐step model with dropout + lr tuning + EarlyStopping)\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "units_list   = [32, 50, 64]\n",
        "batch_sizes  = [8, 16, 32]\n",
        "dropout_list = [0.1, 0.2, 0.3]\n",
        "lr_list      = [1e-2, 1e-3, 1e-4]\n",
        "\n",
        "best_rmse, best_params = np.inf, None\n",
        "\n",
        "for units in units_list:\n",
        "    for dropout in dropout_list:\n",
        "        for batch_size in batch_sizes:\n",
        "            for lr in lr_list:\n",
        "                print(f\"Try: units={units}, batch={batch_size}, \"\n",
        "                      f\"dropout={dropout}, lr={lr}\")\n",
        "\n",
        "                # build model dynamically per-iteration\n",
        "                m = Sequential()\n",
        "                m.add(LSTM(units, activation='tanh', input_shape=(look_back, 1)))\n",
        "                if dropout > 0.0:\n",
        "                    m.add(Dropout(dropout))\n",
        "                m.add(Dense(1))\n",
        "\n",
        "                # compile with Adam at this learning rate\n",
        "                optimizer = Adam(learning_rate=lr)\n",
        "                m.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "                # early stopping on val_loss\n",
        "                es = EarlyStopping(\n",
        "                    monitor='val_loss',\n",
        "                    patience=5,\n",
        "                    restore_best_weights=True,\n",
        "                    verbose=0\n",
        "                )\n",
        "\n",
        "                # train with validation data\n",
        "                hist = m.fit(\n",
        "                    X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[es],\n",
        "                    verbose=0\n",
        "                )\n",
        "\n",
        "                # one-step validation RMSE\n",
        "                val_pred = m.predict(X_val, verbose=0).flatten()\n",
        "                rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "                print(f\"  Val RMSE: {rmse:.4f}\")\n",
        "\n",
        "                if rmse < best_rmse:\n",
        "                    best_rmse, best_params = rmse, (units, batch_size, dropout, lr)\n",
        "                    best_model, best_history = m, hist\n",
        "\n",
        "print(f\"\\nBest → units={best_params[0]}, batch={best_params[1]}, \"\n",
        "      f\"dropout={best_params[2]}, lr={best_params[3]}, RMSE={best_rmse:.4f}\")\n"
      ],
      "metadata": {
        "id": "I6yXV8t9MLn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training & Validation Loss\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(best_history.history['loss'], label='Train Loss')\n",
        "plt.plot(best_history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Training vs. Validation Loss')\n",
        "plt.xlabel('Epoch'); plt.ylabel('MSE'); plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MB0LZYOE8EN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Use the Best Model for Prediction and Forecasting**"
      ],
      "metadata": {
        "id": "imzmPXYiGgr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterative 24‐Month Forecast\n",
        "horizon = 24\n",
        "last_window = monthly_scaled[-look_back:].reshape(1, look_back, 1)\n",
        "preds_scaled = []\n",
        "window = last_window.copy()\n",
        "\n",
        "for _ in range(horizon):\n",
        "    p = best_model.predict(window, verbose=0)[0,0]\n",
        "    preds_scaled.append(p)\n",
        "    # slide window\n",
        "    window = np.concatenate([window[:,1:,:], np.array([[[p]]])], axis=1)\n",
        "\n",
        "pred_scaled = np.array(preds_scaled).reshape(-1,1)\n",
        "forecast = scaler.inverse_transform(pred_scaled).flatten()\n"
      ],
      "metadata": {
        "id": "tv5WKGNeAUGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Forecast\n",
        "import pandas as pd\n",
        "\n",
        "last_date = monthly.index[-1]\n",
        "h_idx     = pd.date_range(last_date + pd.offsets.MonthEnd(1),\n",
        "                          periods=horizon, freq='M')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(monthly.index[-look_back:], monthly.values[-look_back:], label='Input Window')\n",
        "plt.plot(h_idx, forecast, marker='x', label='24‐Month Iterative Forecast')\n",
        "plt.title(\"Oil Price: 24‐Month Iterative LSTM Forecast\")\n",
        "plt.xlabel(\"Date\"); plt.ylabel(\"Price (USD)\"); plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "fBN6xdGeAaWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Validation RMSE in USD (for CI width)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# 1) Predict on your validation set\n",
        "val_pred_scaled = best_model.predict(X_val, verbose=0).flatten()\n",
        "# 2) Invert scaling to USD\n",
        "val_pred_usd = scaler.inverse_transform(val_pred_scaled.reshape(-1,1)).flatten()\n",
        "val_true_usd = scaler.inverse_transform(y_val.reshape(-1,1)).flatten()\n",
        "# 3) Compute RMSE (USD)\n",
        "val_mse      = mean_squared_error(val_true_usd, val_pred_usd)\n",
        "val_rmse_usd = np.sqrt(val_mse)\n",
        "print(f\"Validation RMSE (USD): {val_rmse_usd:.2f}\")\n"
      ],
      "metadata": {
        "id": "TjpiPTpJDQnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build 95% CI around your 24-month forecast\n",
        "ci = 1.96 * val_rmse_usd\n",
        "lower = forecast - ci\n",
        "upper = forecast + ci\n"
      ],
      "metadata": {
        "id": "nTj8DUjjDNfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_latest = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/Advance Research/Assignment 1/\"\n",
        "    \"Oil price data to the current date.csv\",\n",
        "    parse_dates=['Date']\n",
        ")\n",
        "data_latest = data_latest.sort_values('Date').set_index('Date')\n",
        "monthly_latest = data_latest['Price'].resample('M').mean().dropna()\n"
      ],
      "metadata": {
        "id": "m9rpxtgLJndN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MC-Dropout Forecast\n",
        "def mc_dropout_forecast(model, last_window, scaler, horizon=24, n_sims=200):\n",
        "    \"\"\"\n",
        "    Iterative forecasting with dropout active at inference in TF 2.x:\n",
        "    - model(window, training=True) ensures Dropout layers stay on.\n",
        "    \"\"\"\n",
        "    sims = np.zeros((n_sims, horizon))\n",
        "    for sim in range(n_sims):\n",
        "        window = last_window.copy()\n",
        "        preds = []\n",
        "        for _ in range(horizon):\n",
        "            # Forward pass with dropout\n",
        "            p = model(window, training=True).numpy()[0,0]\n",
        "            preds.append(p)\n",
        "            # Slide window forward\n",
        "            window = np.concatenate([window[:,1:,:], [[[p]]]], axis=1)\n",
        "        sims[sim] = preds\n",
        "\n",
        "    # Invert scale: sims shape (n_sims, horizon)\n",
        "    sims_usd = scaler.inverse_transform(sims.T).T  # now (n_sims, horizon)\n",
        "    mean_usd   = sims_usd.mean(axis=0)\n",
        "    lower_usd  = np.percentile(sims_usd, 2.5, axis=0)\n",
        "    upper_usd  = np.percentile(sims_usd, 97.5, axis=0)\n",
        "    return mean_usd, lower_usd, upper_usd\n",
        "\n",
        "\n",
        "last_window = monthly_scaled[-look_back:].reshape(1, look_back, 1)\n",
        "mc_mean, mc_lower, mc_upper = mc_dropout_forecast(\n",
        "    best_model, last_window, scaler, horizon=24, n_sims=200\n",
        ")\n"
      ],
      "metadata": {
        "id": "J3MqfiDRI4TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot MC Dropout CIs vs. Fixed RMSE Band\n",
        "plt.figure(figsize=(10,4))\n",
        "# historical\n",
        "plt.plot(monthly.index, monthly.values, label='Historical')\n",
        "# Current data\n",
        "plt.plot(monthly_latest.index, monthly_latest.values,\n",
        "         linestyle='--', label='Current data')\n",
        "# MC mean forecast\n",
        "plt.plot(h_idx, mc_mean, marker='x', color='orange', label='MC Dropout Mean')\n",
        "# MC CI\n",
        "plt.fill_between(h_idx, mc_lower, mc_upper,\n",
        "                 color='orange', alpha=0.3, label='MC 95% CI')\n",
        "# fixed RMSE band for comparison\n",
        "plt.fill_between(h_idx, lower, upper,\n",
        "                 color='gray', alpha=0.2, label='Fixed ±1.96×RMSE')\n",
        "\n",
        "plt.title('Oil Price: 24-Month Forecast with MC-Dropout CIs')\n",
        "plt.xlabel('Date'); plt.ylabel('Price (USD)'); plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "vdKhZKsHIRsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge Historical, Forecast, and Current CSV Data, Then Plot (with MC-dropout CI)\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "# 1) Build the forecast index (already defined as h_idx)\n",
        "last_hist = monthly.index[-1]\n",
        "h_idx = pd.date_range(last_hist + pd.offsets.MonthEnd(1),\n",
        "                      periods=horizon, freq='M')\n",
        "\n",
        "# 2) Align the live data\n",
        "live_slice = monthly_latest.reindex(h_idx).ffill()\n",
        "\n",
        "# Plot historical\n",
        "plt.plot(monthly.index, monthly.values, label='Historical (to end of training)')\n",
        "\n",
        "# Plot point forecast\n",
        "plt.plot(h_idx, forecast, marker='x', label='Forecast (24 mo)')\n",
        "\n",
        "# Fixed ±1.96×RMSE band\n",
        "plt.fill_between(h_idx, lower, upper,\n",
        "                 color='gray', alpha=0.3, label='Fixed 95% CI')\n",
        "\n",
        "# **New**: MC-dropout 95% CI band\n",
        "plt.fill_between(h_idx, mc_lower, mc_upper,\n",
        "                 color='orange', alpha=0.3, label='MC-dropout 95% CI')\n",
        "\n",
        "# Plot actual current data\n",
        "plt.plot(h_idx, live_slice.values,\n",
        "         linestyle='--', color='green', label='Current data')\n",
        "\n",
        "# Zoom x-axis\n",
        "plt.xlim(monthly.index[-look_back], h_idx[-1])\n",
        "\n",
        "plt.title('Oil Price: Historical, Forecast & Current data with MC-dropout CI')\n",
        "plt.xlabel('Date'); plt.ylabel('Price (USD)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Nhqly9JhP7Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute & Print Final Overlap Metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Align forecast and actual CSV data\n",
        "f = pd.Series(forecast, index=h_idx)\n",
        "a = monthly_latest.reindex(h_idx).ffill()\n",
        "\n",
        "common = f.index.intersection(a.index)\n",
        "f_common = f.loc[common]\n",
        "a_common = a.loc[common]\n",
        "\n",
        "rmse_final = np.sqrt(mean_squared_error(a_common, f_common))\n",
        "mae_final  = mean_absolute_error(a_common, f_common)\n",
        "mape_final = np.mean(np.abs((a_common - f_common) / a_common)) * 100\n",
        "\n",
        "start, end = common[0].date(), common[-1].date()\n",
        "print(f\"Overlap period: {start} to {end}\")\n",
        "print(f\"  RMSE : ${rmse_final:.2f}\")\n",
        "print(f\"  MAE  : ${mae_final:.2f}\")\n",
        "print(f\"  MAPE : {mape_final:.1f}%\")\n"
      ],
      "metadata": {
        "id": "FuAY40BCLAPJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}